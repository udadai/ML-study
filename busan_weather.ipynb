{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CqZCAkv_VVW5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터"
      ],
      "metadata": {
        "id": "ddENB3Zngved"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"OBS_ASOS_TIM_20230114170958.csv\", encoding='cp949')"
      ],
      "metadata": {
        "id": "4VIlx4DTVuZg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pt6QentkWOCK",
        "outputId": "183b3f7c-3a56-4705-d055-67ccedb80f61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    지점 지점명                일시  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  해면기압(hPa)  \\\n",
              "0  159  부산  2022-01-01 01:00    -2.0      NaN      3.6     24     1028.8   \n",
              "1  159  부산  2022-01-01 02:00    -2.3      NaN      2.4     24     1029.3   \n",
              "2  159  부산  2022-01-01 03:00    -2.8      NaN      3.5     27     1029.6   \n",
              "3  159  부산  2022-01-01 04:00    -2.3      NaN      2.4     20     1029.0   \n",
              "4  159  부산  2022-01-01 05:00    -2.2      NaN      4.2     19     1028.5   \n",
              "\n",
              "   시정(10m)  \n",
              "0   5000.0  \n",
              "1   5000.0  \n",
              "2   5000.0  \n",
              "3   5000.0  \n",
              "4   5000.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e20a17-b3b0-4213-9e88-12763c26a049\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>지점</th>\n",
              "      <th>지점명</th>\n",
              "      <th>일시</th>\n",
              "      <th>기온(°C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>해면기압(hPa)</th>\n",
              "      <th>시정(10m)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>159</td>\n",
              "      <td>부산</td>\n",
              "      <td>2022-01-01 01:00</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>24</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>159</td>\n",
              "      <td>부산</td>\n",
              "      <td>2022-01-01 02:00</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>24</td>\n",
              "      <td>1029.3</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>159</td>\n",
              "      <td>부산</td>\n",
              "      <td>2022-01-01 03:00</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.5</td>\n",
              "      <td>27</td>\n",
              "      <td>1029.6</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>159</td>\n",
              "      <td>부산</td>\n",
              "      <td>2022-01-01 04:00</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>20</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>159</td>\n",
              "      <td>부산</td>\n",
              "      <td>2022-01-01 05:00</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.2</td>\n",
              "      <td>19</td>\n",
              "      <td>1028.5</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e20a17-b3b0-4213-9e88-12763c26a049')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90e20a17-b3b0-4213-9e88-12763c26a049 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90e20a17-b3b0-4213-9e88-12763c26a049');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29LMf8d0WQfB",
        "outputId": "75d60e76-2ea2-4fe1-d8d1-9c694bda4364"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8736, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-a7HEURWUIn",
        "outputId": "38475c07-bd4d-4e40-f5f6-a156cc47fe25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['지점', '지점명', '일시', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '해면기압(hPa)',\n",
              "       '시정(10m)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHL2JkhMWedB",
        "outputId": "317f1348-b516-4e42-edc0-1248aad46454"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8736 entries, 0 to 8735\n",
            "Data columns (total 9 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   지점         8736 non-null   int64  \n",
            " 1   지점명        8736 non-null   object \n",
            " 2   일시         8736 non-null   object \n",
            " 3   기온(°C)     8736 non-null   float64\n",
            " 4   강수량(mm)    580 non-null    float64\n",
            " 5   풍속(m/s)    8710 non-null   float64\n",
            " 6   습도(%)      8736 non-null   int64  \n",
            " 7   해면기압(hPa)  8735 non-null   float64\n",
            " 8   시정(10m)    8734 non-null   float64\n",
            "dtypes: float64(5), int64(2), object(2)\n",
            "memory usage: 614.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['지점', '지점명'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "5HAs6e2FWipB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lv6dGRpnohEG",
        "outputId": "cdeeb3d7-7a80-4762-f606-ea7d8498b620"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 일시  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  해면기압(hPa)  시정(10m)\n",
              "0  2022-01-01 01:00    -2.0      NaN      3.6     24     1028.8   5000.0\n",
              "1  2022-01-01 02:00    -2.3      NaN      2.4     24     1029.3   5000.0\n",
              "2  2022-01-01 03:00    -2.8      NaN      3.5     27     1029.6   5000.0\n",
              "3  2022-01-01 04:00    -2.3      NaN      2.4     20     1029.0   5000.0\n",
              "4  2022-01-01 05:00    -2.2      NaN      4.2     19     1028.5   5000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a66305f1-910a-4d06-bce3-34f2d177d101\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일시</th>\n",
              "      <th>기온(°C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>해면기압(hPa)</th>\n",
              "      <th>시정(10m)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-01 01:00</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>24</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-01 02:00</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>24</td>\n",
              "      <td>1029.3</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-01 03:00</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.5</td>\n",
              "      <td>27</td>\n",
              "      <td>1029.6</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-01 04:00</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>20</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-01 05:00</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.2</td>\n",
              "      <td>19</td>\n",
              "      <td>1028.5</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a66305f1-910a-4d06-bce3-34f2d177d101')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a66305f1-910a-4d06-bce3-34f2d177d101 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a66305f1-910a-4d06-bce3-34f2d177d101');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index = pd.to_datetime(df['일시']).dt.floor('T')\n",
        "df = df.iloc[:, 1:]"
      ],
      "metadata": {
        "id": "Ydm24p2nXAKz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "FSkN20PGXRcc",
        "outputId": "476c1f6d-6d0b-4ed5-92b4-982a1b18753e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  해면기압(hPa)  시정(10m)\n",
              "일시                                                                      \n",
              "2022-01-01 01:00:00    -2.0      NaN      3.6     24     1028.8   5000.0\n",
              "2022-01-01 02:00:00    -2.3      NaN      2.4     24     1029.3   5000.0\n",
              "2022-01-01 03:00:00    -2.8      NaN      3.5     27     1029.6   5000.0\n",
              "2022-01-01 04:00:00    -2.3      NaN      2.4     20     1029.0   5000.0\n",
              "2022-01-01 05:00:00    -2.2      NaN      4.2     19     1028.5   5000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e26abfea-de2f-4a79-a74c-a08e7ddbe45a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>기온(°C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>해면기압(hPa)</th>\n",
              "      <th>시정(10m)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일시</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-01 01:00:00</th>\n",
              "      <td>-2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>24</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 02:00:00</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>24</td>\n",
              "      <td>1029.3</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 03:00:00</th>\n",
              "      <td>-2.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.5</td>\n",
              "      <td>27</td>\n",
              "      <td>1029.6</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 04:00:00</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.4</td>\n",
              "      <td>20</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 05:00:00</th>\n",
              "      <td>-2.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.2</td>\n",
              "      <td>19</td>\n",
              "      <td>1028.5</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e26abfea-de2f-4a79-a74c-a08e7ddbe45a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e26abfea-de2f-4a79-a74c-a08e7ddbe45a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e26abfea-de2f-4a79-a74c-a08e7ddbe45a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul9H00WrXdpI",
        "outputId": "bf1f5fce-a87c-4e5e-cfdf-2b465f0cb9b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 8736 entries, 2022-01-01 01:00:00 to 2022-12-31 00:00:00\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   기온(°C)     8736 non-null   float64\n",
            " 1   강수량(mm)    580 non-null    float64\n",
            " 2   풍속(m/s)    8710 non-null   float64\n",
            " 3   습도(%)      8736 non-null   int64  \n",
            " 4   해면기압(hPa)  8735 non-null   float64\n",
            " 5   시정(10m)    8734 non-null   float64\n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 477.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjBRGlFzYZw5",
        "outputId": "e7c0d2ad-00c5-4877-e8e8-c254bbee8bd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "기온(°C)          0\n",
              "강수량(mm)      8156\n",
              "풍속(m/s)        26\n",
              "습도(%)           0\n",
              "해면기압(hPa)       1\n",
              "시정(10m)         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['강수량(mm)', '풍속(m/s)', '해면기압(hPa)', '시정(10m)']:\n",
        "  df[col].fillna(df[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "2nYPcHhBYeby"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHSr2X1YuTK",
        "outputId": "1bb4cf0b-baa8-4826-a22a-93e8f4a80a4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "기온(°C)       0\n",
              "강수량(mm)      0\n",
              "풍속(m/s)      0\n",
              "습도(%)        0\n",
              "해면기압(hPa)    0\n",
              "시정(10m)      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Ig8OamLsYwxK",
        "outputId": "0bf36151-81bf-427f-8dd6-8e2bf98b09ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  해면기압(hPa)  시정(10m)\n",
              "일시                                                                      \n",
              "2022-01-01 01:00:00    -2.0      0.0      3.6     24     1028.8   5000.0\n",
              "2022-01-01 02:00:00    -2.3      0.0      2.4     24     1029.3   5000.0\n",
              "2022-01-01 03:00:00    -2.8      0.0      3.5     27     1029.6   5000.0\n",
              "2022-01-01 04:00:00    -2.3      0.0      2.4     20     1029.0   5000.0\n",
              "2022-01-01 05:00:00    -2.2      0.0      4.2     19     1028.5   5000.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e60541f1-079a-4df0-9f59-f289901271d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>기온(°C)</th>\n",
              "      <th>강수량(mm)</th>\n",
              "      <th>풍속(m/s)</th>\n",
              "      <th>습도(%)</th>\n",
              "      <th>해면기압(hPa)</th>\n",
              "      <th>시정(10m)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일시</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-01 01:00:00</th>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>24</td>\n",
              "      <td>1028.8</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 02:00:00</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>24</td>\n",
              "      <td>1029.3</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 03:00:00</th>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>27</td>\n",
              "      <td>1029.6</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 04:00:00</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>20</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 05:00:00</th>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>19</td>\n",
              "      <td>1028.5</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e60541f1-079a-4df0-9f59-f289901271d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e60541f1-079a-4df0-9f59-f289901271d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e60541f1-079a-4df0-9f59-f289901271d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['일시 (월)'] = pd.to_datetime(df.index).month\n",
        "df['일시 (일)'] = pd.to_datetime(df.index).day\n",
        "df['일시 (시)'] = pd.to_datetime(df.index).hour"
      ],
      "metadata": {
        "id": "clYQOxXBZHBi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "t8p0Qrn6Y-GH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_input = ['일시 (월)', '일시 (일)', '일시 (시)', '강수량(mm)', '풍속(m/s)', '습도(%)', '해면기압(hPa)', '시정(10m)']\n",
        "param_output = '기온(°C)'"
      ],
      "metadata": {
        "id": "PQgTjWwuZaIt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = df[param_input]\n",
        "y_data = df[param_output]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "mYe3ViJHZ4CK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7SBNRe8zaC34"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤포레스트"
      ],
      "metadata": {
        "id": "nbCSm_OiaRYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "Wmxglu-BaGOA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, X_train_scaled, y_train, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik7jhQs1aH-5",
        "outputId": "5c8c620b-172f-47e2-d945-2e9945973583"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9964482330495986 0.9744198046376141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train_scaled, y_train)\n",
        "print(rf.score(X_train_scaled, y_train))\n",
        "print(rf.score(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XBd3qVNew4F",
        "outputId": "227496af-18b6-4cbc-ef00-0de42b1b6a02"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9970492456319845\n",
            "0.979832464388811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "scores = cross_validate(rf, X_train_scaled, y_train, cv=KFold())\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fAVJv58h56b",
        "outputId": "a6f70160-c10a-4d01-d96e-cf3b7aa2d9d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9746840616063359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "scores = cross_validate(rf, X_train_scaled, y_train, cv=splitter)\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aowZRcAiTvB",
        "outputId": "c68dfff3-42ec-4ea9-ffd3-02b41fd010bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9772740541686182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('MAE: {}'.format(mae))\n",
        "print('MSE: {}'.format(mse))\n",
        "print('RMSE: {}'.format(rmse))\n",
        "print('R2 Score: {}'.format(r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tto3SmrRaKjz",
        "outputId": "75767ecc-432c-4f18-fc83-7133512a9be0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.880231590995803\n",
            "MSE: 1.5783567100343376\n",
            "RMSE: 1.2563266732957385\n",
            "R2 Score: 0.979832464388811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형회귀"
      ],
      "metadata": {
        "id": "Vxm3-j9LaPJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "yVEMDdZxaTc9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "print(lr.score(X_train_scaled, y_train))\n",
        "print(lr.score(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zflqHbHwaUo1",
        "outputId": "13613b5f-31df-49cc-ecd5-39f18b79d9da"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6212140578659651\n",
            "0.6305605678498281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lr.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('MAE: {}'.format(mae))\n",
        "print('MSE: {}'.format(mse))\n",
        "print('RMSE: {}'.format(rmse))\n",
        "print('R2 Score: {}'.format(r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI4ukZ-PaW0Z",
        "outputId": "6a87a088-4fe1-4e99-8042-c37565d2e29d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 4.122617624819052\n",
            "MSE: 28.913161128223866\n",
            "RMSE: 5.377095975359178\n",
            "R2 Score: 0.6305605678498281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "9cGBqNl9abix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLVWJWLb6SQa",
        "outputId": "66c2238f-50e3-4a04-a2b8-e02fd89befbd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6115, 8)\n",
            "(2621, 8)\n",
            "(6115,)\n",
            "(2621,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "10fxYDtaaa8i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.LSTM(8, input_shape=(8, 5001)))\n",
        "model.add(keras.layers.Dense(1, activation='relu'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HOxggW5YakFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f15a50-81a5-4bac-b39a-e83a6a3c3eab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 8)                 160320    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,329\n",
            "Trainable params: 160,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = keras.utils.to_categorical(X_train)\n",
        "val_seq = keras.utils.to_categorical(X_test)"
      ],
      "metadata": {
        "id": "ahS1qTrb9lut"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq.shape)\n",
        "print(val_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2B-Knw39ncl",
        "outputId": "3c3c63af-c10c-4295-aa1e-119431f962c2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6115, 8, 5001)\n",
            "(2621, 8, 5001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5', save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_seq, y_train, epochs=500, batch_size=64, validation_data=(val_seq, y_test), callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7GmaXbT8f8r",
        "outputId": "67749279-37b3-46d1-823d-93bb39872685"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "96/96 [==============================] - 7s 47ms/step - loss: 317.4404 - mse: 317.4404 - val_loss: 310.8554 - val_mse: 310.8554\n",
            "Epoch 2/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 315.2827 - mse: 315.2827 - val_loss: 308.5347 - val_mse: 308.5347\n",
            "Epoch 3/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 312.6890 - mse: 312.6890 - val_loss: 305.6917 - val_mse: 305.6917\n",
            "Epoch 4/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 309.4889 - mse: 309.4889 - val_loss: 302.1897 - val_mse: 302.1897\n",
            "Epoch 5/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 305.5574 - mse: 305.5574 - val_loss: 297.8954 - val_mse: 297.8954\n",
            "Epoch 6/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 300.7121 - mse: 300.7121 - val_loss: 292.5975 - val_mse: 292.5975\n",
            "Epoch 7/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 294.8482 - mse: 294.8482 - val_loss: 286.2400 - val_mse: 286.2400\n",
            "Epoch 8/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 287.8130 - mse: 287.8130 - val_loss: 278.7754 - val_mse: 278.7754\n",
            "Epoch 9/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 279.7975 - mse: 279.7975 - val_loss: 270.4323 - val_mse: 270.4323\n",
            "Epoch 10/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 271.0955 - mse: 271.0955 - val_loss: 261.6647 - val_mse: 261.6647\n",
            "Epoch 11/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 262.2039 - mse: 262.2039 - val_loss: 252.9975 - val_mse: 252.9975\n",
            "Epoch 12/500\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 253.7419 - mse: 253.7419 - val_loss: 245.0477 - val_mse: 245.0477\n",
            "Epoch 13/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 246.0907 - mse: 246.0907 - val_loss: 238.0069 - val_mse: 238.0069\n",
            "Epoch 14/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 239.4197 - mse: 239.4197 - val_loss: 231.9113 - val_mse: 231.9113\n",
            "Epoch 15/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 233.7230 - mse: 233.7230 - val_loss: 226.7156 - val_mse: 226.7156\n",
            "Epoch 16/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 228.7830 - mse: 228.7830 - val_loss: 222.1700 - val_mse: 222.1700\n",
            "Epoch 17/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 224.4435 - mse: 224.4435 - val_loss: 218.1230 - val_mse: 218.1230\n",
            "Epoch 18/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 220.4989 - mse: 220.4989 - val_loss: 214.3927 - val_mse: 214.3927\n",
            "Epoch 19/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 216.8443 - mse: 216.8443 - val_loss: 210.9328 - val_mse: 210.9328\n",
            "Epoch 20/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 213.4094 - mse: 213.4094 - val_loss: 207.6400 - val_mse: 207.6400\n",
            "Epoch 21/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 210.1595 - mse: 210.1595 - val_loss: 204.4886 - val_mse: 204.4886\n",
            "Epoch 22/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 207.0038 - mse: 207.0038 - val_loss: 201.4665 - val_mse: 201.4665\n",
            "Epoch 23/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 203.9797 - mse: 203.9797 - val_loss: 198.5299 - val_mse: 198.5299\n",
            "Epoch 24/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 201.0527 - mse: 201.0527 - val_loss: 195.6865 - val_mse: 195.6865\n",
            "Epoch 25/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 198.2057 - mse: 198.2057 - val_loss: 192.9380 - val_mse: 192.9380\n",
            "Epoch 26/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 195.4550 - mse: 195.4550 - val_loss: 190.2733 - val_mse: 190.2733\n",
            "Epoch 27/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 192.7871 - mse: 192.7871 - val_loss: 187.6869 - val_mse: 187.6869\n",
            "Epoch 28/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 190.1957 - mse: 190.1957 - val_loss: 185.1867 - val_mse: 185.1867\n",
            "Epoch 29/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 187.6726 - mse: 187.6726 - val_loss: 182.7431 - val_mse: 182.7431\n",
            "Epoch 30/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 185.2385 - mse: 185.2385 - val_loss: 180.3868 - val_mse: 180.3868\n",
            "Epoch 31/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 182.8641 - mse: 182.8641 - val_loss: 178.0786 - val_mse: 178.0786\n",
            "Epoch 32/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 180.5531 - mse: 180.5531 - val_loss: 175.8504 - val_mse: 175.8504\n",
            "Epoch 33/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 178.3200 - mse: 178.3200 - val_loss: 173.6844 - val_mse: 173.6844\n",
            "Epoch 34/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 176.1594 - mse: 176.1594 - val_loss: 171.5798 - val_mse: 171.5798\n",
            "Epoch 35/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 174.0239 - mse: 174.0239 - val_loss: 169.5142 - val_mse: 169.5142\n",
            "Epoch 36/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 171.9487 - mse: 171.9487 - val_loss: 167.5143 - val_mse: 167.5143\n",
            "Epoch 37/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 169.9367 - mse: 169.9367 - val_loss: 165.5519 - val_mse: 165.5519\n",
            "Epoch 38/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 167.9496 - mse: 167.9496 - val_loss: 163.6471 - val_mse: 163.6471\n",
            "Epoch 39/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 166.0376 - mse: 166.0376 - val_loss: 161.7765 - val_mse: 161.7765\n",
            "Epoch 40/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 164.1501 - mse: 164.1501 - val_loss: 159.9508 - val_mse: 159.9508\n",
            "Epoch 41/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 162.3241 - mse: 162.3241 - val_loss: 158.1686 - val_mse: 158.1686\n",
            "Epoch 42/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 160.5259 - mse: 160.5259 - val_loss: 156.4304 - val_mse: 156.4304\n",
            "Epoch 43/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 158.7609 - mse: 158.7609 - val_loss: 154.7204 - val_mse: 154.7204\n",
            "Epoch 44/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 157.0319 - mse: 157.0319 - val_loss: 153.0462 - val_mse: 153.0462\n",
            "Epoch 45/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 155.3468 - mse: 155.3468 - val_loss: 151.4045 - val_mse: 151.4045\n",
            "Epoch 46/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 153.6831 - mse: 153.6831 - val_loss: 149.7887 - val_mse: 149.7887\n",
            "Epoch 47/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 152.0511 - mse: 152.0511 - val_loss: 148.2043 - val_mse: 148.2043\n",
            "Epoch 48/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 150.4440 - mse: 150.4440 - val_loss: 146.6443 - val_mse: 146.6443\n",
            "Epoch 49/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 148.8728 - mse: 148.8728 - val_loss: 145.1181 - val_mse: 145.1181\n",
            "Epoch 50/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 147.3222 - mse: 147.3222 - val_loss: 143.6195 - val_mse: 143.6195\n",
            "Epoch 51/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 145.8070 - mse: 145.8070 - val_loss: 142.1488 - val_mse: 142.1488\n",
            "Epoch 52/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 144.3158 - mse: 144.3158 - val_loss: 140.6974 - val_mse: 140.6974\n",
            "Epoch 53/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 142.8370 - mse: 142.8370 - val_loss: 139.2697 - val_mse: 139.2697\n",
            "Epoch 54/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 141.3922 - mse: 141.3922 - val_loss: 137.8701 - val_mse: 137.8701\n",
            "Epoch 55/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 139.9698 - mse: 139.9698 - val_loss: 136.4849 - val_mse: 136.4849\n",
            "Epoch 56/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 138.5561 - mse: 138.5561 - val_loss: 135.1163 - val_mse: 135.1163\n",
            "Epoch 57/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 137.1776 - mse: 137.1776 - val_loss: 133.7825 - val_mse: 133.7825\n",
            "Epoch 58/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 135.8215 - mse: 135.8215 - val_loss: 132.4643 - val_mse: 132.4643\n",
            "Epoch 59/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 134.4773 - mse: 134.4773 - val_loss: 131.1645 - val_mse: 131.1645\n",
            "Epoch 60/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 133.1494 - mse: 133.1494 - val_loss: 129.8864 - val_mse: 129.8864\n",
            "Epoch 61/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 131.8606 - mse: 131.8606 - val_loss: 128.6384 - val_mse: 128.6384\n",
            "Epoch 62/500\n",
            "96/96 [==============================] - 4s 46ms/step - loss: 130.5870 - mse: 130.5870 - val_loss: 127.3962 - val_mse: 127.3962\n",
            "Epoch 63/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 129.3131 - mse: 129.3131 - val_loss: 126.1675 - val_mse: 126.1675\n",
            "Epoch 64/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 128.0717 - mse: 128.0717 - val_loss: 124.9654 - val_mse: 124.9654\n",
            "Epoch 65/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 126.8506 - mse: 126.8506 - val_loss: 123.7833 - val_mse: 123.7833\n",
            "Epoch 66/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 125.6440 - mse: 125.6440 - val_loss: 122.6246 - val_mse: 122.6246\n",
            "Epoch 67/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 124.4508 - mse: 124.4508 - val_loss: 121.4613 - val_mse: 121.4613\n",
            "Epoch 68/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 123.2796 - mse: 123.2796 - val_loss: 120.3353 - val_mse: 120.3353\n",
            "Epoch 69/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 122.1195 - mse: 122.1195 - val_loss: 119.2138 - val_mse: 119.2138\n",
            "Epoch 70/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 120.9920 - mse: 120.9920 - val_loss: 118.1244 - val_mse: 118.1244\n",
            "Epoch 71/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 119.8637 - mse: 119.8637 - val_loss: 117.0328 - val_mse: 117.0328\n",
            "Epoch 72/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 118.7534 - mse: 118.7534 - val_loss: 115.9722 - val_mse: 115.9722\n",
            "Epoch 73/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 117.6628 - mse: 117.6628 - val_loss: 114.9106 - val_mse: 114.9106\n",
            "Epoch 74/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 116.5965 - mse: 116.5965 - val_loss: 113.8837 - val_mse: 113.8837\n",
            "Epoch 75/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 115.5433 - mse: 115.5433 - val_loss: 112.8754 - val_mse: 112.8754\n",
            "Epoch 76/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 114.5027 - mse: 114.5027 - val_loss: 111.8619 - val_mse: 111.8619\n",
            "Epoch 77/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 113.4768 - mse: 113.4768 - val_loss: 110.8889 - val_mse: 110.8889\n",
            "Epoch 78/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 112.4682 - mse: 112.4682 - val_loss: 109.9123 - val_mse: 109.9123\n",
            "Epoch 79/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 111.4847 - mse: 111.4847 - val_loss: 108.9648 - val_mse: 108.9648\n",
            "Epoch 80/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 110.5011 - mse: 110.5011 - val_loss: 108.0205 - val_mse: 108.0205\n",
            "Epoch 81/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 109.5399 - mse: 109.5399 - val_loss: 107.0963 - val_mse: 107.0963\n",
            "Epoch 82/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 108.5857 - mse: 108.5857 - val_loss: 106.1892 - val_mse: 106.1892\n",
            "Epoch 83/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 107.6610 - mse: 107.6610 - val_loss: 105.3008 - val_mse: 105.3008\n",
            "Epoch 84/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 106.7371 - mse: 106.7371 - val_loss: 104.4163 - val_mse: 104.4163\n",
            "Epoch 85/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 105.8472 - mse: 105.8472 - val_loss: 103.5639 - val_mse: 103.5639\n",
            "Epoch 86/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 104.9548 - mse: 104.9548 - val_loss: 102.7127 - val_mse: 102.7127\n",
            "Epoch 87/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 104.0912 - mse: 104.0912 - val_loss: 101.8876 - val_mse: 101.8876\n",
            "Epoch 88/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 103.2375 - mse: 103.2375 - val_loss: 101.0694 - val_mse: 101.0694\n",
            "Epoch 89/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 102.3939 - mse: 102.3939 - val_loss: 100.2689 - val_mse: 100.2689\n",
            "Epoch 90/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 101.5799 - mse: 101.5799 - val_loss: 99.4889 - val_mse: 99.4889\n",
            "Epoch 91/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 100.7742 - mse: 100.7742 - val_loss: 98.7216 - val_mse: 98.7216\n",
            "Epoch 92/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 99.9810 - mse: 99.9810 - val_loss: 97.9662 - val_mse: 97.9662\n",
            "Epoch 93/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 99.1957 - mse: 99.1957 - val_loss: 97.2256 - val_mse: 97.2256\n",
            "Epoch 94/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 98.4353 - mse: 98.4353 - val_loss: 96.5059 - val_mse: 96.5059\n",
            "Epoch 95/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 97.6986 - mse: 97.6986 - val_loss: 95.8027 - val_mse: 95.8027\n",
            "Epoch 96/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 96.9727 - mse: 96.9727 - val_loss: 95.1117 - val_mse: 95.1117\n",
            "Epoch 97/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 96.2631 - mse: 96.2631 - val_loss: 94.4396 - val_mse: 94.4396\n",
            "Epoch 98/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 95.5618 - mse: 95.5618 - val_loss: 93.7772 - val_mse: 93.7772\n",
            "Epoch 99/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 94.8754 - mse: 94.8754 - val_loss: 93.1298 - val_mse: 93.1298\n",
            "Epoch 100/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 94.1967 - mse: 94.1967 - val_loss: 92.4895 - val_mse: 92.4895\n",
            "Epoch 101/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 93.5466 - mse: 93.5466 - val_loss: 91.8766 - val_mse: 91.8766\n",
            "Epoch 102/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 92.9036 - mse: 92.9036 - val_loss: 91.2711 - val_mse: 91.2711\n",
            "Epoch 103/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 92.2860 - mse: 92.2860 - val_loss: 90.6844 - val_mse: 90.6844\n",
            "Epoch 104/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 91.6693 - mse: 91.6693 - val_loss: 90.1145 - val_mse: 90.1145\n",
            "Epoch 105/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 91.0773 - mse: 91.0773 - val_loss: 89.5511 - val_mse: 89.5511\n",
            "Epoch 106/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 90.4878 - mse: 90.4878 - val_loss: 89.0075 - val_mse: 89.0075\n",
            "Epoch 107/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 89.9188 - mse: 89.9188 - val_loss: 88.4674 - val_mse: 88.4674\n",
            "Epoch 108/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 89.3700 - mse: 89.3700 - val_loss: 87.9579 - val_mse: 87.9579\n",
            "Epoch 109/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 88.8364 - mse: 88.8364 - val_loss: 87.4618 - val_mse: 87.4618\n",
            "Epoch 110/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 88.3076 - mse: 88.3076 - val_loss: 86.9711 - val_mse: 86.9711\n",
            "Epoch 111/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 87.8069 - mse: 87.8069 - val_loss: 86.5027 - val_mse: 86.5027\n",
            "Epoch 112/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 87.3141 - mse: 87.3141 - val_loss: 86.0495 - val_mse: 86.0495\n",
            "Epoch 113/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 86.8440 - mse: 86.8440 - val_loss: 85.6122 - val_mse: 85.6122\n",
            "Epoch 114/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 86.3691 - mse: 86.3691 - val_loss: 85.1773 - val_mse: 85.1773\n",
            "Epoch 115/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 85.9200 - mse: 85.9200 - val_loss: 84.7663 - val_mse: 84.7663\n",
            "Epoch 116/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 85.4761 - mse: 85.4761 - val_loss: 84.3654 - val_mse: 84.3654\n",
            "Epoch 117/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 85.0533 - mse: 85.0533 - val_loss: 83.9752 - val_mse: 83.9752\n",
            "Epoch 118/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 84.6328 - mse: 84.6328 - val_loss: 83.5999 - val_mse: 83.5999\n",
            "Epoch 119/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 84.2366 - mse: 84.2366 - val_loss: 83.2507 - val_mse: 83.2507\n",
            "Epoch 120/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 83.8553 - mse: 83.8553 - val_loss: 82.9149 - val_mse: 82.9149\n",
            "Epoch 121/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 83.4831 - mse: 83.4831 - val_loss: 82.5854 - val_mse: 82.5854\n",
            "Epoch 122/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 83.1198 - mse: 83.1198 - val_loss: 82.2618 - val_mse: 82.2618\n",
            "Epoch 123/500\n",
            "96/96 [==============================] - 5s 50ms/step - loss: 82.7737 - mse: 82.7737 - val_loss: 81.9592 - val_mse: 81.9592\n",
            "Epoch 124/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 82.4428 - mse: 82.4428 - val_loss: 81.6674 - val_mse: 81.6674\n",
            "Epoch 125/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 82.1309 - mse: 82.1309 - val_loss: 81.3869 - val_mse: 81.3869\n",
            "Epoch 126/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 81.8227 - mse: 81.8227 - val_loss: 81.1249 - val_mse: 81.1249\n",
            "Epoch 127/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 81.5310 - mse: 81.5310 - val_loss: 80.8791 - val_mse: 80.8791\n",
            "Epoch 128/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 81.2505 - mse: 81.2505 - val_loss: 80.6422 - val_mse: 80.6422\n",
            "Epoch 129/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 80.9822 - mse: 80.9822 - val_loss: 80.4287 - val_mse: 80.4287\n",
            "Epoch 130/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 80.7167 - mse: 80.7167 - val_loss: 80.2261 - val_mse: 80.2261\n",
            "Epoch 131/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 80.4777 - mse: 80.4777 - val_loss: 80.0409 - val_mse: 80.0409\n",
            "Epoch 132/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 80.2662 - mse: 80.2662 - val_loss: 79.8643 - val_mse: 79.8643\n",
            "Epoch 133/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 80.0534 - mse: 80.0534 - val_loss: 79.6958 - val_mse: 79.6958\n",
            "Epoch 134/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 79.8622 - mse: 79.8622 - val_loss: 79.5342 - val_mse: 79.5342\n",
            "Epoch 135/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 79.6833 - mse: 79.6833 - val_loss: 79.3906 - val_mse: 79.3906\n",
            "Epoch 136/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 79.5180 - mse: 79.5180 - val_loss: 79.2573 - val_mse: 79.2573\n",
            "Epoch 137/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 79.3651 - mse: 79.3651 - val_loss: 79.1292 - val_mse: 79.1292\n",
            "Epoch 138/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 79.2163 - mse: 79.2163 - val_loss: 79.0123 - val_mse: 79.0123\n",
            "Epoch 139/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 79.0854 - mse: 79.0854 - val_loss: 78.9180 - val_mse: 78.9180\n",
            "Epoch 140/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 78.9720 - mse: 78.9720 - val_loss: 78.8202 - val_mse: 78.8202\n",
            "Epoch 141/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.8593 - mse: 78.8593 - val_loss: 78.7429 - val_mse: 78.7429\n",
            "Epoch 142/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.7646 - mse: 78.7646 - val_loss: 78.6707 - val_mse: 78.6707\n",
            "Epoch 143/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.6729 - mse: 78.6729 - val_loss: 78.6019 - val_mse: 78.6019\n",
            "Epoch 144/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 78.5918 - mse: 78.5918 - val_loss: 78.5488 - val_mse: 78.5488\n",
            "Epoch 145/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.5199 - mse: 78.5199 - val_loss: 78.4963 - val_mse: 78.4963\n",
            "Epoch 146/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.4557 - mse: 78.4557 - val_loss: 78.4495 - val_mse: 78.4495\n",
            "Epoch 147/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.3953 - mse: 78.3953 - val_loss: 78.4118 - val_mse: 78.4118\n",
            "Epoch 148/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.3403 - mse: 78.3403 - val_loss: 78.3740 - val_mse: 78.3740\n",
            "Epoch 149/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 78.2936 - mse: 78.2936 - val_loss: 78.3416 - val_mse: 78.3416\n",
            "Epoch 150/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.2532 - mse: 78.2532 - val_loss: 78.3171 - val_mse: 78.3171\n",
            "Epoch 151/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.2167 - mse: 78.2167 - val_loss: 78.2948 - val_mse: 78.2948\n",
            "Epoch 152/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.1795 - mse: 78.1795 - val_loss: 78.2736 - val_mse: 78.2736\n",
            "Epoch 153/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.1529 - mse: 78.1529 - val_loss: 78.2542 - val_mse: 78.2542\n",
            "Epoch 154/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.1256 - mse: 78.1256 - val_loss: 78.2366 - val_mse: 78.2366\n",
            "Epoch 155/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.1030 - mse: 78.1030 - val_loss: 78.2170 - val_mse: 78.2170\n",
            "Epoch 156/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.0789 - mse: 78.0789 - val_loss: 78.1903 - val_mse: 78.1903\n",
            "Epoch 157/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 78.0437 - mse: 78.0437 - val_loss: 78.1431 - val_mse: 78.1431\n",
            "Epoch 158/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 77.9699 - mse: 77.9699 - val_loss: 78.0591 - val_mse: 78.0591\n",
            "Epoch 159/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 77.8375 - mse: 77.8375 - val_loss: 77.8868 - val_mse: 77.8868\n",
            "Epoch 160/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 77.6826 - mse: 77.6826 - val_loss: 77.6298 - val_mse: 77.6298\n",
            "Epoch 161/500\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 77.5868 - mse: 77.5868 - val_loss: 77.5181 - val_mse: 77.5181\n",
            "Epoch 162/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 77.4751 - mse: 77.4751 - val_loss: 77.4352 - val_mse: 77.4352\n",
            "Epoch 163/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 77.3726 - mse: 77.3726 - val_loss: 77.3016 - val_mse: 77.3016\n",
            "Epoch 164/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 77.2735 - mse: 77.2735 - val_loss: 77.2191 - val_mse: 77.2191\n",
            "Epoch 165/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 77.1768 - mse: 77.1768 - val_loss: 77.0786 - val_mse: 77.0786\n",
            "Epoch 166/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 77.0550 - mse: 77.0550 - val_loss: 76.9250 - val_mse: 76.9250\n",
            "Epoch 167/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 76.7838 - mse: 76.7838 - val_loss: 76.6927 - val_mse: 76.6927\n",
            "Epoch 168/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 76.4726 - mse: 76.4726 - val_loss: 76.4469 - val_mse: 76.4469\n",
            "Epoch 169/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 76.1672 - mse: 76.1672 - val_loss: 76.2090 - val_mse: 76.2090\n",
            "Epoch 170/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 75.9782 - mse: 75.9782 - val_loss: 75.9720 - val_mse: 75.9720\n",
            "Epoch 171/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 75.8816 - mse: 75.8816 - val_loss: 75.8878 - val_mse: 75.8878\n",
            "Epoch 172/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 75.8302 - mse: 75.8302 - val_loss: 75.8120 - val_mse: 75.8120\n",
            "Epoch 173/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 75.7051 - mse: 75.7051 - val_loss: 75.3922 - val_mse: 75.3922\n",
            "Epoch 174/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 75.4056 - mse: 75.4056 - val_loss: 74.6828 - val_mse: 74.6828\n",
            "Epoch 175/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 74.9577 - mse: 74.9577 - val_loss: 73.9636 - val_mse: 73.9636\n",
            "Epoch 176/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 74.5419 - mse: 74.5419 - val_loss: 73.5162 - val_mse: 73.5162\n",
            "Epoch 177/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 73.9088 - mse: 73.9088 - val_loss: 72.8243 - val_mse: 72.8243\n",
            "Epoch 178/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 73.2294 - mse: 73.2294 - val_loss: 71.5428 - val_mse: 71.5428\n",
            "Epoch 179/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 72.3545 - mse: 72.3545 - val_loss: 70.8609 - val_mse: 70.8609\n",
            "Epoch 180/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 71.6662 - mse: 71.6662 - val_loss: 70.1235 - val_mse: 70.1235\n",
            "Epoch 181/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 70.7834 - mse: 70.7834 - val_loss: 69.4283 - val_mse: 69.4283\n",
            "Epoch 182/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 69.8327 - mse: 69.8327 - val_loss: 68.6464 - val_mse: 68.6464\n",
            "Epoch 183/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 68.2911 - mse: 68.2911 - val_loss: 66.9661 - val_mse: 66.9661\n",
            "Epoch 184/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 66.5681 - mse: 66.5681 - val_loss: 65.4359 - val_mse: 65.4359\n",
            "Epoch 185/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 65.0945 - mse: 65.0945 - val_loss: 63.6934 - val_mse: 63.6934\n",
            "Epoch 186/500\n",
            "96/96 [==============================] - 5s 51ms/step - loss: 64.0998 - mse: 64.0998 - val_loss: 62.6779 - val_mse: 62.6779\n",
            "Epoch 187/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 63.3343 - mse: 63.3343 - val_loss: 61.8541 - val_mse: 61.8541\n",
            "Epoch 188/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 62.6818 - mse: 62.6818 - val_loss: 60.8961 - val_mse: 60.8961\n",
            "Epoch 189/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 62.0798 - mse: 62.0798 - val_loss: 60.6418 - val_mse: 60.6418\n",
            "Epoch 190/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 61.6292 - mse: 61.6292 - val_loss: 60.3016 - val_mse: 60.3016\n",
            "Epoch 191/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 60.9363 - mse: 60.9363 - val_loss: 59.3779 - val_mse: 59.3779\n",
            "Epoch 192/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 59.8295 - mse: 59.8295 - val_loss: 58.0212 - val_mse: 58.0212\n",
            "Epoch 193/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 58.7258 - mse: 58.7258 - val_loss: 56.5199 - val_mse: 56.5199\n",
            "Epoch 194/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 57.1366 - mse: 57.1366 - val_loss: 54.4184 - val_mse: 54.4184\n",
            "Epoch 195/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 55.0617 - mse: 55.0617 - val_loss: 52.9871 - val_mse: 52.9871\n",
            "Epoch 196/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 52.3317 - mse: 52.3317 - val_loss: 50.4343 - val_mse: 50.4343\n",
            "Epoch 197/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 50.4689 - mse: 50.4689 - val_loss: 48.3172 - val_mse: 48.3172\n",
            "Epoch 198/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 48.8276 - mse: 48.8276 - val_loss: 47.5575 - val_mse: 47.5575\n",
            "Epoch 199/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 48.1035 - mse: 48.1035 - val_loss: 46.7965 - val_mse: 46.7965\n",
            "Epoch 200/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 47.7246 - mse: 47.7246 - val_loss: 46.4289 - val_mse: 46.4289\n",
            "Epoch 201/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 47.2975 - mse: 47.2975 - val_loss: 45.9692 - val_mse: 45.9692\n",
            "Epoch 202/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 46.8958 - mse: 46.8958 - val_loss: 45.2561 - val_mse: 45.2561\n",
            "Epoch 203/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 46.4805 - mse: 46.4805 - val_loss: 44.9107 - val_mse: 44.9107\n",
            "Epoch 204/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 46.0295 - mse: 46.0295 - val_loss: 44.4642 - val_mse: 44.4642\n",
            "Epoch 205/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 45.7397 - mse: 45.7397 - val_loss: 43.9656 - val_mse: 43.9656\n",
            "Epoch 206/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 45.1506 - mse: 45.1506 - val_loss: 43.7694 - val_mse: 43.7694\n",
            "Epoch 207/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 44.7686 - mse: 44.7686 - val_loss: 43.4643 - val_mse: 43.4643\n",
            "Epoch 208/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 44.2736 - mse: 44.2736 - val_loss: 43.2115 - val_mse: 43.2115\n",
            "Epoch 209/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 43.9085 - mse: 43.9085 - val_loss: 42.7010 - val_mse: 42.7010\n",
            "Epoch 210/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 43.4370 - mse: 43.4370 - val_loss: 42.1022 - val_mse: 42.1022\n",
            "Epoch 211/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 42.9819 - mse: 42.9819 - val_loss: 41.8366 - val_mse: 41.8366\n",
            "Epoch 212/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 42.7972 - mse: 42.7972 - val_loss: 41.7579 - val_mse: 41.7579\n",
            "Epoch 213/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 42.5477 - mse: 42.5477 - val_loss: 41.4462 - val_mse: 41.4462\n",
            "Epoch 214/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 42.3066 - mse: 42.3066 - val_loss: 41.3518 - val_mse: 41.3518\n",
            "Epoch 215/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 42.0490 - mse: 42.0490 - val_loss: 41.1665 - val_mse: 41.1665\n",
            "Epoch 216/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 41.7268 - mse: 41.7268 - val_loss: 40.9947 - val_mse: 40.9947\n",
            "Epoch 217/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 41.3727 - mse: 41.3727 - val_loss: 40.8447 - val_mse: 40.8447\n",
            "Epoch 218/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 40.9604 - mse: 40.9604 - val_loss: 40.7493 - val_mse: 40.7493\n",
            "Epoch 219/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 40.5419 - mse: 40.5419 - val_loss: 40.4970 - val_mse: 40.4970\n",
            "Epoch 220/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 39.9703 - mse: 39.9703 - val_loss: 39.6299 - val_mse: 39.6299\n",
            "Epoch 221/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 39.4204 - mse: 39.4204 - val_loss: 39.4452 - val_mse: 39.4452\n",
            "Epoch 222/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 38.9153 - mse: 38.9153 - val_loss: 39.1733 - val_mse: 39.1733\n",
            "Epoch 223/500\n",
            "96/96 [==============================] - 3s 35ms/step - loss: 38.2905 - mse: 38.2905 - val_loss: 39.0590 - val_mse: 39.0590\n",
            "Epoch 224/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 37.8967 - mse: 37.8967 - val_loss: 38.2912 - val_mse: 38.2912\n",
            "Epoch 225/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 37.4178 - mse: 37.4178 - val_loss: 37.9673 - val_mse: 37.9673\n",
            "Epoch 226/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 37.1176 - mse: 37.1176 - val_loss: 37.7073 - val_mse: 37.7073\n",
            "Epoch 227/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 36.8147 - mse: 36.8147 - val_loss: 37.4485 - val_mse: 37.4485\n",
            "Epoch 228/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 36.4912 - mse: 36.4912 - val_loss: 37.3810 - val_mse: 37.3810\n",
            "Epoch 229/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 36.3687 - mse: 36.3687 - val_loss: 37.3050 - val_mse: 37.3050\n",
            "Epoch 230/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 36.2945 - mse: 36.2945 - val_loss: 37.0600 - val_mse: 37.0600\n",
            "Epoch 231/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 35.9709 - mse: 35.9709 - val_loss: 36.4858 - val_mse: 36.4858\n",
            "Epoch 232/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 35.7445 - mse: 35.7445 - val_loss: 36.3007 - val_mse: 36.3007\n",
            "Epoch 233/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 35.5627 - mse: 35.5627 - val_loss: 36.0756 - val_mse: 36.0756\n",
            "Epoch 234/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 35.3589 - mse: 35.3589 - val_loss: 35.8316 - val_mse: 35.8316\n",
            "Epoch 235/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 35.1620 - mse: 35.1620 - val_loss: 35.5863 - val_mse: 35.5863\n",
            "Epoch 236/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 34.9699 - mse: 34.9699 - val_loss: 35.3560 - val_mse: 35.3560\n",
            "Epoch 237/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 34.7751 - mse: 34.7751 - val_loss: 35.1427 - val_mse: 35.1427\n",
            "Epoch 238/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 34.5879 - mse: 34.5879 - val_loss: 34.9722 - val_mse: 34.9722\n",
            "Epoch 239/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 34.4160 - mse: 34.4160 - val_loss: 34.8160 - val_mse: 34.8160\n",
            "Epoch 240/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 34.2650 - mse: 34.2650 - val_loss: 34.6767 - val_mse: 34.6767\n",
            "Epoch 241/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 34.1395 - mse: 34.1395 - val_loss: 34.5481 - val_mse: 34.5481\n",
            "Epoch 242/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 34.0339 - mse: 34.0339 - val_loss: 34.4564 - val_mse: 34.4564\n",
            "Epoch 243/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.9489 - mse: 33.9489 - val_loss: 34.3701 - val_mse: 34.3701\n",
            "Epoch 244/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.8771 - mse: 33.8771 - val_loss: 34.3099 - val_mse: 34.3099\n",
            "Epoch 245/500\n",
            "96/96 [==============================] - 5s 51ms/step - loss: 33.8177 - mse: 33.8177 - val_loss: 34.2593 - val_mse: 34.2593\n",
            "Epoch 246/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.7679 - mse: 33.7679 - val_loss: 34.2145 - val_mse: 34.2145\n",
            "Epoch 247/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.7246 - mse: 33.7246 - val_loss: 34.1788 - val_mse: 34.1788\n",
            "Epoch 248/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.6930 - mse: 33.6930 - val_loss: 34.1487 - val_mse: 34.1487\n",
            "Epoch 249/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.6659 - mse: 33.6659 - val_loss: 34.1196 - val_mse: 34.1196\n",
            "Epoch 250/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.6426 - mse: 33.6426 - val_loss: 34.0973 - val_mse: 34.0973\n",
            "Epoch 251/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.6251 - mse: 33.6251 - val_loss: 34.0788 - val_mse: 34.0788\n",
            "Epoch 252/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.6103 - mse: 33.6103 - val_loss: 34.0633 - val_mse: 34.0633\n",
            "Epoch 253/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5970 - mse: 33.5970 - val_loss: 34.0486 - val_mse: 34.0486\n",
            "Epoch 254/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5855 - mse: 33.5855 - val_loss: 34.0362 - val_mse: 34.0362\n",
            "Epoch 255/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.5752 - mse: 33.5752 - val_loss: 34.0252 - val_mse: 34.0252\n",
            "Epoch 256/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.5659 - mse: 33.5659 - val_loss: 34.0146 - val_mse: 34.0146\n",
            "Epoch 257/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.5572 - mse: 33.5572 - val_loss: 34.0048 - val_mse: 34.0048\n",
            "Epoch 258/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5491 - mse: 33.5491 - val_loss: 33.9959 - val_mse: 33.9959\n",
            "Epoch 259/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5413 - mse: 33.5413 - val_loss: 33.9873 - val_mse: 33.9873\n",
            "Epoch 260/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5341 - mse: 33.5341 - val_loss: 33.9793 - val_mse: 33.9793\n",
            "Epoch 261/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5270 - mse: 33.5270 - val_loss: 33.9717 - val_mse: 33.9717\n",
            "Epoch 262/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.5201 - mse: 33.5201 - val_loss: 33.9641 - val_mse: 33.9641\n",
            "Epoch 263/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.5139 - mse: 33.5139 - val_loss: 33.9571 - val_mse: 33.9571\n",
            "Epoch 264/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.5075 - mse: 33.5075 - val_loss: 33.9505 - val_mse: 33.9505\n",
            "Epoch 265/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.5015 - mse: 33.5015 - val_loss: 33.9443 - val_mse: 33.9443\n",
            "Epoch 266/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.4952 - mse: 33.4952 - val_loss: 33.9378 - val_mse: 33.9378\n",
            "Epoch 267/500\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 33.4890 - mse: 33.4890 - val_loss: 33.9315 - val_mse: 33.9315\n",
            "Epoch 268/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.4830 - mse: 33.4830 - val_loss: 33.9255 - val_mse: 33.9255\n",
            "Epoch 269/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.4767 - mse: 33.4767 - val_loss: 33.9193 - val_mse: 33.9193\n",
            "Epoch 270/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4703 - mse: 33.4703 - val_loss: 33.9132 - val_mse: 33.9132\n",
            "Epoch 271/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4640 - mse: 33.4640 - val_loss: 33.9068 - val_mse: 33.9068\n",
            "Epoch 272/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4575 - mse: 33.4575 - val_loss: 33.9005 - val_mse: 33.9005\n",
            "Epoch 273/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4509 - mse: 33.4509 - val_loss: 33.8943 - val_mse: 33.8943\n",
            "Epoch 274/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4442 - mse: 33.4442 - val_loss: 33.8883 - val_mse: 33.8883\n",
            "Epoch 275/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.4373 - mse: 33.4373 - val_loss: 33.8820 - val_mse: 33.8820\n",
            "Epoch 276/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 33.4303 - mse: 33.4303 - val_loss: 33.8755 - val_mse: 33.8755\n",
            "Epoch 277/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4231 - mse: 33.4231 - val_loss: 33.8693 - val_mse: 33.8693\n",
            "Epoch 278/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4158 - mse: 33.4158 - val_loss: 33.8630 - val_mse: 33.8630\n",
            "Epoch 279/500\n",
            "96/96 [==============================] - 4s 36ms/step - loss: 33.4082 - mse: 33.4082 - val_loss: 33.8565 - val_mse: 33.8565\n",
            "Epoch 280/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.4001 - mse: 33.4001 - val_loss: 33.8497 - val_mse: 33.8497\n",
            "Epoch 281/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.3920 - mse: 33.3920 - val_loss: 33.8425 - val_mse: 33.8425\n",
            "Epoch 282/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.3838 - mse: 33.3838 - val_loss: 33.8358 - val_mse: 33.8358\n",
            "Epoch 283/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.3751 - mse: 33.3751 - val_loss: 33.8288 - val_mse: 33.8288\n",
            "Epoch 284/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3668 - mse: 33.3668 - val_loss: 33.8222 - val_mse: 33.8222\n",
            "Epoch 285/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3593 - mse: 33.3593 - val_loss: 33.8156 - val_mse: 33.8156\n",
            "Epoch 286/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3505 - mse: 33.3505 - val_loss: 33.8083 - val_mse: 33.8083\n",
            "Epoch 287/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3422 - mse: 33.3422 - val_loss: 33.8011 - val_mse: 33.8011\n",
            "Epoch 288/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3342 - mse: 33.3342 - val_loss: 33.7941 - val_mse: 33.7941\n",
            "Epoch 289/500\n",
            "96/96 [==============================] - 3s 36ms/step - loss: 33.3265 - mse: 33.3265 - val_loss: 33.7876 - val_mse: 33.7876\n",
            "Epoch 290/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3190 - mse: 33.3190 - val_loss: 33.7815 - val_mse: 33.7815\n",
            "Epoch 291/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.3113 - mse: 33.3113 - val_loss: 33.7755 - val_mse: 33.7755\n",
            "Epoch 292/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.3034 - mse: 33.3034 - val_loss: 33.7697 - val_mse: 33.7697\n",
            "Epoch 293/500\n",
            "96/96 [==============================] - 4s 36ms/step - loss: 33.2958 - mse: 33.2958 - val_loss: 33.7634 - val_mse: 33.7634\n",
            "Epoch 294/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2883 - mse: 33.2883 - val_loss: 33.7576 - val_mse: 33.7576\n",
            "Epoch 295/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.2799 - mse: 33.2799 - val_loss: 33.7507 - val_mse: 33.7507\n",
            "Epoch 296/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2724 - mse: 33.2724 - val_loss: 33.7445 - val_mse: 33.7445\n",
            "Epoch 297/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.2647 - mse: 33.2647 - val_loss: 33.7384 - val_mse: 33.7384\n",
            "Epoch 298/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2563 - mse: 33.2563 - val_loss: 33.7323 - val_mse: 33.7323\n",
            "Epoch 299/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.2485 - mse: 33.2485 - val_loss: 33.7265 - val_mse: 33.7265\n",
            "Epoch 300/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.2409 - mse: 33.2409 - val_loss: 33.7206 - val_mse: 33.7206\n",
            "Epoch 301/500\n",
            "96/96 [==============================] - 4s 36ms/step - loss: 33.2330 - mse: 33.2330 - val_loss: 33.7147 - val_mse: 33.7147\n",
            "Epoch 302/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2248 - mse: 33.2248 - val_loss: 33.7082 - val_mse: 33.7082\n",
            "Epoch 303/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2167 - mse: 33.2167 - val_loss: 33.7018 - val_mse: 33.7018\n",
            "Epoch 304/500\n",
            "96/96 [==============================] - 5s 51ms/step - loss: 33.2093 - mse: 33.2093 - val_loss: 33.6961 - val_mse: 33.6961\n",
            "Epoch 305/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.2018 - mse: 33.2018 - val_loss: 33.6899 - val_mse: 33.6899\n",
            "Epoch 306/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.1947 - mse: 33.1947 - val_loss: 33.6841 - val_mse: 33.6841\n",
            "Epoch 307/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1873 - mse: 33.1873 - val_loss: 33.6779 - val_mse: 33.6779\n",
            "Epoch 308/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.1801 - mse: 33.1801 - val_loss: 33.6718 - val_mse: 33.6718\n",
            "Epoch 309/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1731 - mse: 33.1731 - val_loss: 33.6652 - val_mse: 33.6652\n",
            "Epoch 310/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1658 - mse: 33.1658 - val_loss: 33.6587 - val_mse: 33.6587\n",
            "Epoch 311/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1589 - mse: 33.1589 - val_loss: 33.6524 - val_mse: 33.6524\n",
            "Epoch 312/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1518 - mse: 33.1518 - val_loss: 33.6463 - val_mse: 33.6463\n",
            "Epoch 313/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1448 - mse: 33.1448 - val_loss: 33.6403 - val_mse: 33.6403\n",
            "Epoch 314/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1377 - mse: 33.1377 - val_loss: 33.6341 - val_mse: 33.6341\n",
            "Epoch 315/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.1310 - mse: 33.1310 - val_loss: 33.6279 - val_mse: 33.6279\n",
            "Epoch 316/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.1240 - mse: 33.1240 - val_loss: 33.6223 - val_mse: 33.6223\n",
            "Epoch 317/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1172 - mse: 33.1172 - val_loss: 33.6162 - val_mse: 33.6162\n",
            "Epoch 318/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1105 - mse: 33.1105 - val_loss: 33.6098 - val_mse: 33.6098\n",
            "Epoch 319/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.1034 - mse: 33.1034 - val_loss: 33.6033 - val_mse: 33.6033\n",
            "Epoch 320/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.0964 - mse: 33.0964 - val_loss: 33.5982 - val_mse: 33.5982\n",
            "Epoch 321/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0898 - mse: 33.0898 - val_loss: 33.5921 - val_mse: 33.5921\n",
            "Epoch 322/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0829 - mse: 33.0829 - val_loss: 33.5856 - val_mse: 33.5856\n",
            "Epoch 323/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0764 - mse: 33.0764 - val_loss: 33.5803 - val_mse: 33.5803\n",
            "Epoch 324/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0693 - mse: 33.0693 - val_loss: 33.5738 - val_mse: 33.5738\n",
            "Epoch 325/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.0620 - mse: 33.0620 - val_loss: 33.5670 - val_mse: 33.5670\n",
            "Epoch 326/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0552 - mse: 33.0552 - val_loss: 33.5613 - val_mse: 33.5613\n",
            "Epoch 327/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0485 - mse: 33.0485 - val_loss: 33.5552 - val_mse: 33.5552\n",
            "Epoch 328/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.0420 - mse: 33.0420 - val_loss: 33.5504 - val_mse: 33.5504\n",
            "Epoch 329/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.0346 - mse: 33.0346 - val_loss: 33.5446 - val_mse: 33.5446\n",
            "Epoch 330/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 33.0280 - mse: 33.0280 - val_loss: 33.5377 - val_mse: 33.5377\n",
            "Epoch 331/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0209 - mse: 33.0209 - val_loss: 33.5331 - val_mse: 33.5331\n",
            "Epoch 332/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0144 - mse: 33.0144 - val_loss: 33.5259 - val_mse: 33.5259\n",
            "Epoch 333/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 33.0074 - mse: 33.0074 - val_loss: 33.5198 - val_mse: 33.5198\n",
            "Epoch 334/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 33.0011 - mse: 33.0011 - val_loss: 33.5142 - val_mse: 33.5142\n",
            "Epoch 335/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9949 - mse: 32.9949 - val_loss: 33.5086 - val_mse: 33.5086\n",
            "Epoch 336/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9881 - mse: 32.9881 - val_loss: 33.5051 - val_mse: 33.5051\n",
            "Epoch 337/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9821 - mse: 32.9821 - val_loss: 33.4960 - val_mse: 33.4960\n",
            "Epoch 338/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9747 - mse: 32.9747 - val_loss: 33.4883 - val_mse: 33.4883\n",
            "Epoch 339/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 32.9685 - mse: 32.9685 - val_loss: 33.4837 - val_mse: 33.4837\n",
            "Epoch 340/500\n",
            "96/96 [==============================] - 4s 39ms/step - loss: 32.9615 - mse: 32.9615 - val_loss: 33.4758 - val_mse: 33.4758\n",
            "Epoch 341/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9543 - mse: 32.9543 - val_loss: 33.4689 - val_mse: 33.4689\n",
            "Epoch 342/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9473 - mse: 32.9473 - val_loss: 33.4656 - val_mse: 33.4656\n",
            "Epoch 343/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9411 - mse: 32.9411 - val_loss: 33.4576 - val_mse: 33.4576\n",
            "Epoch 344/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9345 - mse: 32.9345 - val_loss: 33.4525 - val_mse: 33.4525\n",
            "Epoch 345/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9283 - mse: 32.9283 - val_loss: 33.4463 - val_mse: 33.4463\n",
            "Epoch 346/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9220 - mse: 32.9220 - val_loss: 33.4407 - val_mse: 33.4407\n",
            "Epoch 347/500\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 32.9153 - mse: 32.9153 - val_loss: 33.4326 - val_mse: 33.4326\n",
            "Epoch 348/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9086 - mse: 32.9086 - val_loss: 33.4255 - val_mse: 33.4255\n",
            "Epoch 349/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9011 - mse: 32.9011 - val_loss: 33.5567 - val_mse: 33.5567\n",
            "Epoch 350/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9131 - mse: 32.9131 - val_loss: 33.5792 - val_mse: 33.5792\n",
            "Epoch 351/500\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 32.9077 - mse: 32.9077 - val_loss: 33.5652 - val_mse: 33.5652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-Icx0-8kIGd0",
        "outputId": "3421f749-45c4-46a2-b019-82bccb380927"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}